# Visual Search System
An  visual search system that allows users to search image repositories using natural language queries. 

# Project Stucture
```
pb-assignment
â”œâ”€ .dockerignore               # Specifies files/folders to exclude from Docker image build
â”œâ”€ app                         # FastAPI application folder
â”‚  â””â”€ main.py                  # Entry point for FastAPI app
â”œâ”€ benchmarking_retriever.ipynb # Jupyter notebook for benchmarking retrieval performance
â”œâ”€ dockerfile                  # Instructions to build Docker image
â”œâ”€ docs                        # Documentation folder
â”‚  â”œâ”€ Image-search-problem-statement.docx # Problem statement description
â”‚  â””â”€ System Architecture.docx            # High-level architecture design doc
â”œâ”€ End_to_end_example.ipynb    # Jupyter notebook showing full workflow example
â”œâ”€ README.md                   # Project description, setup instructions
â”œâ”€ requirements.txt            # Python dependencies
â”œâ”€ search_app.py               # Gradio seach application
â”œâ”€ src                         # Core source code
â”‚  â”œâ”€ explain_images.py        # Module to generate explanations/descriptions for images
â”‚  â”œâ”€ ingest_images.py         # Module to ingest/preprocess images into vector DB
â”‚  â”œâ”€ semantic_search.py       # Implements semantic search logic
â”‚  â”œâ”€ vector_store.py          # Creates vector store using ChromaDB
â”œâ”€ tests                       # Unit/integration tests
â”‚  â””â”€ test_searcher.py         # Tests cases
â””â”€ utils                       # Utility/helper functions
   â”œâ”€ download_images.py       # Script for downloading images from external sources
   â”œâ”€ embedding_utils.py       # Utilities for creating/managing embeddings
   â”œâ”€ image_utils.py           # General image processing helpers
```

## ğŸš€ Features
- Store and index images with embeddings.
- Perform semantic search with natural language queries.
- Generate AI-driven explanations for retrieved images.
- REST API built with FastAPI.
- Persistent vector database using ChromaDB.
- Containerized deployment with Docker.

## ğŸ› ï¸ Setup & Installation


Create a virtual environment and activate it:

```
python -m venv .venv
# Windows
.venv\Scripts\activate
# Linux / macOS
source .venv/bin/activate

```

Install dependencies. First install PyTorch (CUDA 12.8 example; use CPU build if needed):

```
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
Then install the rest:
pip install -r requirements.txt
```

## Batch Add Images to ChromaDB
To add images from a directory to ChromaDB, run:

```
python -m src.ingest_images
```

## Running the App
Run with Uvicorn:
```
uvicorn app.main:app --host 0.0.0.0 --port 8000

```
run the search app:

```
Python search_app.py
```

Once running, the app is available at http://localhost:8000 and API docs are at http://localhost:8000/docs


## Running Tests

Run the test suite with:
```
pytest -q
```


## ğŸ³ Docker Deployment

Build the Docker image:

```
docker build -t pb-assignment:latest .
```

Run the container with a persistent ChromaDB volume:
```
docker run -p 8000:8000 -v /local/path/to/chroma_db:/app/chroma_db pb-assignment:latest

```

The API will be accessible at http://localhost:8000/docs


## âœ… Example Workflow
1. Add images â†’ embeddings stored in ChromaDB.
2. Search with natural language query.
3. Retrieve top-k similar images + AI-driven explanations.


## Important Notes
- Ensure GPU drivers and CUDA version match the installed PyTorch build.
- By default, ChromaDB persists in ./chroma_db/. Tests use a temporary database.
- For production, always mount a persistent volume as shown in the Docker section.
- Due to lack of openai keys i am using a lmstudio model for generating explanations. Need to change when openai key is available.
